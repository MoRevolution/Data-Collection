{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fd524a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "from pathlib import Path \n",
    "# from datetime import datetime, timezone, timedelta  ## incase timezone modifcations are needed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "\n",
    "PAR_LENGTH = 150 # in number of words\n",
    "FILTER_REQ = 0.7 # evaluation value for number of paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063ca846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoRevolution\\Desktop\\College\\P&R\\Research_LowSES\\Data Collection\\Reddit Search Keywords\\Manual Search Keywords.txt\n",
      "C:\\Users\\MoRevolution\\Desktop\\College\\P&R\\Research_LowSES\\Data Collection\\Reddit Search Keywords\\Modified Keywords .txt\n",
      "C:\\Users\\MoRevolution\\Desktop\\College\\P&R\\Research_LowSES\\Data Collection\\Reddit Search Keywords\\Modified Keywords.txt\n",
      "C:\\Users\\MoRevolution\\Desktop\\College\\P&R\\Research_LowSES\\Data Collection\\Reddit Search Keywords\\SVO Search Keywords.txt\n",
      "Manual Search Keywords\n",
      "Modified Keywords \n",
      "Modified Keywords\n",
      "SVO Search Keywords\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(r\"C:\\Users\\MoRevolution\\Desktop\\College\\P&R\\Research_LowSES\\Data Collection\\Reddit Search Keywords/*.txt\", \n",
    "                   recursive = True)\n",
    "\n",
    "for f in files: \n",
    "    print(f)\n",
    "\n",
    "filenames = []\n",
    "for i in range(len(files)): \n",
    "    filenames.append(files[i][files[i].rfind(\"\\\\\")+1:-4])\n",
    "\n",
    "for f in filenames: \n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01172339",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d7326f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"can't pay for school\", 'struggling with tuition', 'rejected because of finances when applying to college', 'imposer syndrome in college ', 'imposter syndrome in a competitive highschool', 'school is too expensive', \"can't afford tuition \", 'first-gen college student guilt ', 'first-gen college student family pressure', 'first-gen college student struggling with finances', 'lack of emotional support from parents in college', \"my family can't afford to pay school for me \", \"i can't afford a dorm\"], [\"tried hard in school OR dropped out school OR I was the poorest kid in class OR i can't afford a dorm\", \"i can't afford a dorm OR school is too expensive OR can't pay for school OR first-gen college student struggling with finance\", 'growing in poor family OR I come from low income family of substance abusers OR grew up with single mum OR grew up with single father', 'growing in poor family OR I come from low income family of substance abusers OR first-gen college student family pressure', \"grew up with single mum OR grew up with single father OR my family can't afford to pay school for me\", 'I was the poorest kid in class OR it is hard for me to connect ', 'imposter syndrome in a competitive highschool OR imposer syndrome in college '], [\"tried hard in school OR dropped out school OR I was the poorest kid in class OR i can't afford a dorm\", \"i can't afford a dorm OR school is too expensive OR can't pay for school OR first-gen college student struggling with finance\", 'growing in poor family OR I come from low income family of substance abusers OR grew up with single mum OR grew up with single father', 'growing in poor family OR I come from low income family of substance abusers OR first-gen college student family pressure', \"grew up with single mum OR grew up with single father OR my family can't afford to pay school for me\", 'I was the poorest kid in class OR it is hard for me to connect ', 'imposter syndrome in a competitive highschool OR imposer syndrome in college '], ['tried hard in school ', 'dropped out school ', 'grew up with single mum', 'I was the poorest kid in class', 'growing in poor family', 'I come from low income family of substance abusers ', 'feel like I did not belong in school ', 'I grew up relatively poor ', 'it is hard for me to connect ']]\n"
     ]
    }
   ],
   "source": [
    "keyword_list = []\n",
    "master_keyword_list = []\n",
    "filename_counter = 0\n",
    "\n",
    "for f in files: \n",
    "    with open(f, 'r') as file:\n",
    "        keyword_list = []\n",
    "        for line in file:\n",
    "            keyword_list.append(line.strip('\\n')) \n",
    "            \n",
    "    keyword_list = [i for i in keyword_list if i]\n",
    "    master_keyword_list.append(keyword_list)\n",
    "\n",
    "print(master_keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f80b1f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'body'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'body'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MoRevolution\\Desktop\\College\\P&R\\Research_LowSES\\Data Collection\\Sumbission Dump Demo_trial.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MoRevolution/Desktop/College/P%26R/Research_LowSES/Data%20Collection/Sumbission%20Dump%20Demo_trial.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame([thing\u001b[39m.\u001b[39md_ \u001b[39mfor\u001b[39;00m thing \u001b[39min\u001b[39;00m subs])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MoRevolution/Desktop/College/P%26R/Research_LowSES/Data%20Collection/Sumbission%20Dump%20Demo_trial.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m ddf \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39mfrom_pandas(df, npartitions\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/MoRevolution/Desktop/College/P%26R/Research_LowSES/Data%20Collection/Sumbission%20Dump%20Demo_trial.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m ddf[\u001b[39m\"\u001b[39m\u001b[39mNumber of Paragraphs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ddf[\u001b[39m\"\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m n: \u001b[39mlen\u001b[39m(n\u001b[39m.\u001b[39msplit())\u001b[39m/\u001b[39mPAR_LENGTH) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MoRevolution/Desktop/College/P%26R/Research_LowSES/Data%20Collection/Sumbission%20Dump%20Demo_trial.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#filtered data frame with many \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MoRevolution/Desktop/College/P%26R/Research_LowSES/Data%20Collection/Sumbission%20Dump%20Demo_trial.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m dff_filtered \u001b[39m=\u001b[39m ddf[ddf[\u001b[39m\"\u001b[39m\u001b[39mNumber of Paragraphs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m FILTER_REQ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\dask\\dataframe\\core.py:4589\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4586\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[key]\n\u001b[0;32m   4588\u001b[0m \u001b[39m# error is raised from pandas\u001b[39;00m\n\u001b[1;32m-> 4589\u001b[0m meta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_meta[_extract_meta(key)]\n\u001b[0;32m   4590\u001b[0m dsk \u001b[39m=\u001b[39m partitionwise_graph(operator\u001b[39m.\u001b[39mgetitem, name, \u001b[39mself\u001b[39m, key)\n\u001b[0;32m   4591\u001b[0m graph \u001b[39m=\u001b[39m HighLevelGraph\u001b[39m.\u001b[39mfrom_collections(name, dsk, dependencies\u001b[39m=\u001b[39m[\u001b[39mself\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'body'"
     ]
    }
   ],
   "source": [
    "# Suggestions\n",
    "    ## write a script that tries out multiple word combinations for all of the keywords already provided \n",
    "    ## consider using cudf instead of pandas for faster dataframe processing\n",
    "    ## test this code using dask for CPU parallel computing\n",
    "subreddit_list = [\"college\", \"AskReddit\", \"science\", \"psychology\", \"socialwork\", \"personalfinance\", \"financialaid\"]\n",
    "for keyword_n in master_keyword_list:\n",
    "    count = 0 \n",
    "    for keywords in keyword_list: \n",
    "        for subreddit_n in subreddit_list:   \n",
    "            subs = api.search_submissions(\n",
    "                subreddit= subreddit_n,\n",
    "                q= keywords,\n",
    "                filter = [ 'author', 'selftext', 'url', 'permalink', 'subreddit', 'title'],\n",
    "                # metadata = \"false\",   \n",
    "                # max_results_per_request= 500\n",
    "                )\n",
    "\n",
    "            # Set display\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "            df = pd.DataFrame([thing.d_ for thing in subs])\n",
    "            ddf = dd.from_pandas(df, npartitions=10)\n",
    "\n",
    "            ddf[\"Number of Paragraphs\"] = ddf[\"body\"].apply(lambda n: len(n.split())/PAR_LENGTH) \n",
    "            #filtered data frame with many \n",
    "            dff_filtered = ddf[ddf[\"Number of Paragraphs\"] >= FILTER_REQ]\n",
    "\n",
    "            filepath = Path('Data Dumb/Reddit_1/Submissions/'+ subreddit_n +'/'+filenames[filename_counter]+'/Keyword_'+ str(count)+'.csv')\n",
    "            filepath.parent.mkdir(parents = True, exist_ok = True)\n",
    "            ddf.to_csv(filepath)\n",
    "            count += 1 \n",
    "    filename_counter += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17b2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
