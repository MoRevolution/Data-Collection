Motti and Stephanie

    Pending
-- compile the results from the EDA notebook into one separate functions to call
-- encode the whole 2018-01 dataset using multiprocessing via gpu (might need CUDA installation)
-- play around with filtering percentage to see which one is best

    Completed
-- DONE tokenize and lemmatize the narratives before encoding
-- DONE recreate requirements.txt
-- DONE try encoding the narratives instead of the clustered keywords 
-- DONE add Jupyter git dif to repo