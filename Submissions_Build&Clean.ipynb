{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fd524a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psaw import PushshiftAPI\n",
    "#from pmaw import PushshiftAPI\n",
    "from pathlib import Path \n",
    "# from datetime import datetime, timezone, timedelta  ## incase timezone modifcations are needed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "import math\n",
    "\n",
    "PAR_LENGTH = 150 # in number of words\n",
    "FILTER_REQ = 0.7 # evaluation value for number of paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ca846",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(r\"C:\\Users\\MoRevolution\\Desktop\\College\\P&R\\Research_LowSES\\Data Collection\\Reddit Search Keywords/*.txt\", \n",
    "                   recursive = True)\n",
    "\n",
    "for f in files: \n",
    "    print(f)\n",
    "\n",
    "filenames = []\n",
    "for i in range(len(files)): \n",
    "    filenames.append(files[i][files[i].rfind(\"\\\\\")+1:-4])\n",
    "\n",
    "for f in filenames: \n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01172339",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7326f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_list = []\n",
    "master_keyword_list = []\n",
    "filename_counter = 0\n",
    "\n",
    "for f in files: \n",
    "    with open(f, 'r') as file:\n",
    "        keyword_list = []\n",
    "        for line in file:\n",
    "            keyword_list.append(line.strip('\\n')) \n",
    "            \n",
    "    keyword_list = [i for i in keyword_list if i]\n",
    "    master_keyword_list.append(keyword_list)\n",
    "\n",
    "# print(master_keyword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c734cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_list = [\"college\", \"AskReddit\", \"science\", \"psychology\", \"socialwork\", \"personalfinance\", \"financialaid\"]\n",
    "limit = 1000\n",
    "num_workers = 16*2\n",
    "columnNames = ['author', 'selftext', 'url', 'permalink', 'subreddit', 'title', 'keyword', 'keyword_category', 'Number_of_Paragraphs']\n",
    "keyword_id = [\"MAN\", \"MDF\", \"SVO\"]\n",
    "\n",
    "count = 0\n",
    "\n",
    "df_final = pd.DataFrame()\n",
    "for keywords in master_keyword_list: \n",
    "    for subreddit in subreddit_list: \n",
    "        for keyword in keywords: \n",
    "            subs = api.search_submissions(\n",
    "                subreddit= subreddit,\n",
    "                q= keyword,\n",
    "                filter = ['author', 'selftext', 'url', 'permalink', 'subreddit', 'title'],\n",
    "                limit = limit, \n",
    "                num_workers = num_workers\n",
    "                # metadata = \"false\",   \n",
    "                # max_results_per_request= 500\n",
    "            )\n",
    "            \n",
    "            df = pd.DataFrame([rows.d_ for rows in subs])\n",
    "            # df[\"keyword_category\"] = keyword_id[count]\n",
    "            df[\"keyword\"] = keyword\n",
    "            try: \n",
    "                df[\"Number_of_Paragraphs\"] = df['selftext'].apply(lambda n: len(n.split())/PAR_LENGTH)\n",
    "            except: \n",
    "                continue\n",
    "\n",
    "            df = df[df[\"Number_of_Paragraphs\"] >= FILTER_REQ]\n",
    "            df_final = pd.concat([df_final, df])\n",
    "    df_final.to_csv(\"Data Set\"/keyword_id[count]+\".csv\", index= False)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54823744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.columns\n",
    "df_final.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67419043",
   "metadata": {},
   "source": [
    "Working Trial, only to categorize data frames into separate directories based on keywords used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggestions\n",
    "    ## write a script that tries out multiple word combinations for all of the keywords already provided \n",
    "    ## consider using cudf instead of pandas for faster dataframe processing\n",
    "    ## test this code using dask for CPU parallel computing\n",
    "subreddit_list = [\"college\", \"AskReddit\", \"science\", \"psychology\", \"socialwork\", \"personalfinance\", \"financialaid\"]\n",
    "limit = 1000\n",
    "num_workers = 16*2\n",
    "\n",
    "for keyword_n in master_keyword_list:\n",
    "    count = 0 \n",
    "    for keywords in keyword_list: \n",
    "        for subreddit_n in subreddit_list:   \n",
    "            subs = api.search_submissions(\n",
    "                subreddit= subreddit_n,\n",
    "                q= keywords,\n",
    "                filter = [ 'author', 'selftext', 'url', 'permalink', 'subreddit', 'title'],\n",
    "                # metadata = \"false\",   \n",
    "                # max_results_per_request= 500\n",
    "                limit = limit, \n",
    "                num_workers = num_workers\n",
    "                )\n",
    "            \n",
    "            # Set display\n",
    "            pd.set_option('display.max_rows', None)\n",
    "            pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "            df = pd.DataFrame([row for row in subs])\n",
    "            ddf = dd.from_pandas(df, npartitions=6)\n",
    "\n",
    "            try: \n",
    "                ddf[\"Number of Paragraphs\"] = ddf['selftext'].apply(lambda n: len(n.split())/PAR_LENGTH)\n",
    "            except:\n",
    "\n",
    "                continue\n",
    "                \n",
    "            df_filtered = ddf[ddf[\"Number of Paragraphs\"] >= FILTER_REQ]\n",
    "\n",
    "            filepath = Path('C:/Users/MoRevolution/Desktop/College/Data Dump/Reddit_1/Submissions/'+ subreddit_n +'/'+filenames[filename_counter]+'/Keyword_'+ str(count)+'.csv')\n",
    "            filepath.parent.mkdir(parents = True, exist_ok = True)\n",
    "            df_filtered.to_csv(filepath,index=False, single_file=True)\n",
    "            count += 1 \n",
    "    filename_counter += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0234241",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "- Fix problem with apostrophes being replaced by three different symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b01ff0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>created</th>\n",
       "      <th>keyword</th>\n",
       "      <th>Number_of_Paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Real_Librarian_3294</td>\n",
       "      <td>1669165200</td>\n",
       "      <td>/r/college/comments/z2ave9/will_i_have_to_drop...</td>\n",
       "      <td>Things have been rough on my college journey. ...</td>\n",
       "      <td>college</td>\n",
       "      <td>Will I have to dropout?</td>\n",
       "      <td>https://www.reddit.com/r/college/comments/z2av...</td>\n",
       "      <td>1.669187e+09</td>\n",
       "      <td>can't pay for school</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spodosolluvr</td>\n",
       "      <td>1669137743</td>\n",
       "      <td>/r/college/comments/z1z9nc/renting_in_college_...</td>\n",
       "      <td>Hi everyone!! I'm a junior going to a large re...</td>\n",
       "      <td>college</td>\n",
       "      <td>renting in college help</td>\n",
       "      <td>https://www.reddit.com/r/college/comments/z1z9...</td>\n",
       "      <td>1.669159e+09</td>\n",
       "      <td>can't pay for school</td>\n",
       "      <td>4.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thecoolan</td>\n",
       "      <td>1668323192</td>\n",
       "      <td>/r/college/comments/ytugtj/i_think_im_gonna_dr...</td>\n",
       "      <td>&amp;amp;#x200B;\\n\\n***I don't think anybody will ...</td>\n",
       "      <td>college</td>\n",
       "      <td>I think I'm gonna drop out; I regret ever goin...</td>\n",
       "      <td>https://www.reddit.com/r/college/comments/ytug...</td>\n",
       "      <td>1.668345e+09</td>\n",
       "      <td>can't pay for school</td>\n",
       "      <td>2.386667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BATZ202</td>\n",
       "      <td>1668179293</td>\n",
       "      <td>/r/college/comments/ysd45e/i_feel_so_tired_of_...</td>\n",
       "      <td>I'm going through college by myself, my parent...</td>\n",
       "      <td>college</td>\n",
       "      <td>I feel so tired of everything</td>\n",
       "      <td>https://www.reddit.com/r/college/comments/ysd4...</td>\n",
       "      <td>1.668201e+09</td>\n",
       "      <td>can't pay for school</td>\n",
       "      <td>1.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qweezek</td>\n",
       "      <td>1668022332</td>\n",
       "      <td>/r/college/comments/yqt06e/i_am_depressed_beca...</td>\n",
       "      <td>So, first thing I want to say is that I am not...</td>\n",
       "      <td>college</td>\n",
       "      <td>I am depressed because my parents pay for my s...</td>\n",
       "      <td>https://www.reddit.com/r/college/comments/yqt0...</td>\n",
       "      <td>1.668044e+09</td>\n",
       "      <td>can't pay for school</td>\n",
       "      <td>4.793333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author  created_utc  \\\n",
       "0  Real_Librarian_3294   1669165200   \n",
       "1         spodosolluvr   1669137743   \n",
       "2            thecoolan   1668323192   \n",
       "3              BATZ202   1668179293   \n",
       "4              qweezek   1668022332   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/college/comments/z2ave9/will_i_have_to_drop...   \n",
       "1  /r/college/comments/z1z9nc/renting_in_college_...   \n",
       "2  /r/college/comments/ytugtj/i_think_im_gonna_dr...   \n",
       "3  /r/college/comments/ysd45e/i_feel_so_tired_of_...   \n",
       "4  /r/college/comments/yqt06e/i_am_depressed_beca...   \n",
       "\n",
       "                                            selftext subreddit  \\\n",
       "0  Things have been rough on my college journey. ...   college   \n",
       "1  Hi everyone!! I'm a junior going to a large re...   college   \n",
       "2  &amp;#x200B;\\n\\n***I don't think anybody will ...   college   \n",
       "3  I'm going through college by myself, my parent...   college   \n",
       "4  So, first thing I want to say is that I am not...   college   \n",
       "\n",
       "                                               title  \\\n",
       "0                            Will I have to dropout?   \n",
       "1                            renting in college help   \n",
       "2  I think I'm gonna drop out; I regret ever goin...   \n",
       "3                      I feel so tired of everything   \n",
       "4  I am depressed because my parents pay for my s...   \n",
       "\n",
       "                                                 url       created  \\\n",
       "0  https://www.reddit.com/r/college/comments/z2av...  1.669187e+09   \n",
       "1  https://www.reddit.com/r/college/comments/z1z9...  1.669159e+09   \n",
       "2  https://www.reddit.com/r/college/comments/ytug...  1.668345e+09   \n",
       "3  https://www.reddit.com/r/college/comments/ysd4...  1.668201e+09   \n",
       "4  https://www.reddit.com/r/college/comments/yqt0...  1.668044e+09   \n",
       "\n",
       "                keyword  Number_of_Paragraphs  \n",
       "0  can't pay for school              0.840000  \n",
       "1  can't pay for school              4.433333  \n",
       "2  can't pay for school              2.386667  \n",
       "3  can't pay for school              1.993333  \n",
       "4  can't pay for school              4.793333  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dd.read_csv('Data Set/Man.csv')\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016f92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['selftext'] = ddf['selftext'].replace('â€™','\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8cbfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\MoRevolution\\\\Desktop\\\\College\\\\P&R\\\\Research_LowSES\\\\Data Collection\\\\Data Set\\\\Filtered and SQL\\\\Man.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.to_csv(\"Data Set/Filtered and SQL/Man.csv\",index = False, single_file = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c18b1c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_Frame.to_sql() missing 1 required positional argument: 'uri'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MoRevolution\\Desktop\\College\\P&R\\Research_LowSES\\Data Collection\\Sumbissions_Build&Clean.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MoRevolution/Desktop/College/P%26R/Research_LowSES/Data%20Collection/Sumbissions_Build%26Clean.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ddf\u001b[39m.\u001b[39;49mto_sql(\u001b[39m\"\u001b[39;49m\u001b[39mData Set\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: _Frame.to_sql() missing 1 required positional argument: 'uri'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac4e22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
